{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrtmFa8IAtps"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUn1Z--HIHSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c789db6-d235-4c49-ef66-bcba6b57965f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting audiomentations\n",
            "  Downloading audiomentations-0.36.0-py3-none-any.whl (80 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/80.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m71.7/80.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (1.25.2)\n",
            "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.10.2.post1)\n",
            "Requirement already satisfied: scipy<1.13,>=1.4 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (1.11.4)\n",
            "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.3.7)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2024.6.2)\n",
            "Installing collected packages: audiomentations\n",
            "Successfully installed audiomentations-0.36.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import shutil\n",
        "import torch\n",
        "import random\n",
        "import math\n",
        "import h5py\n",
        "import torchaudio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio.transforms as T\n",
        "import torch.optim as optim\n",
        "from sklearn.manifold import TSNE\n",
        "from torch.optim import lr_scheduler\n",
        "from google.colab import drive\n",
        "from google.colab import runtime\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset, Subset\n",
        "from torchvision import models, transforms\n",
        "from torchvision.transforms import v2\n",
        "from torchsummary import summary\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "!pip install audiomentations\n",
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, TimeMask\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrAl3KiDATum"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File('/content/drive/My Drive/Projects/NeuraBeat/Data/train_data_raw.h5', 'r') as train_file:\n",
        "    train_data = np.array(train_file['data'])\n",
        "    train_labels = np.array(train_file['labels'])\n",
        "\n",
        "# Load validation data from HDF5 file\n",
        "with h5py.File('/content/drive/My Drive/Projects/NeuraBeat/Data/val_data_raw.h5', 'r') as val_file:\n",
        "    val_data = np.array(val_file['data'])\n",
        "    val_labels = np.array(val_file['labels'])"
      ],
      "metadata": {
        "id": "2_vWL-vh52PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHrmA-6ouybO"
      },
      "source": [
        "MNIST (Testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWGQaxV6uuit"
      },
      "outputs": [],
      "source": [
        "# mean, std = 0.1307, 0.3081\n",
        "\n",
        "# # Define transforms\n",
        "# transform = v2.Compose([\n",
        "#     v2.Resize((64, 64)),\n",
        "#     v2.ToImage(),\n",
        "#     v2.ToDtype(torch.float32, scale=True),\n",
        "#     v2.Normalize((mean,), (std,))\n",
        "# ])\n",
        "\n",
        "# # Load datasets\n",
        "# train_dataset = MNIST('../data/MNIST', train=True, download=True, transform=transform)\n",
        "# test_dataset = MNIST('../data/MNIST', train=False, download=True, transform=transform)\n",
        "\n",
        "# # Define the target number of samples\n",
        "# num_train_samples = 6400\n",
        "# num_val_samples = 1600\n",
        "\n",
        "# # Shuffle and select a subset of the training dataset\n",
        "# train_indices = np.random.permutation(len(train_dataset))[:num_train_samples]\n",
        "# train_subset = Subset(train_dataset, train_indices)\n",
        "\n",
        "# # Shuffle and select a subset of the validation dataset\n",
        "# val_indices = np.random.permutation(len(test_dataset))[:num_val_samples]\n",
        "# val_subset = Subset(test_dataset, val_indices)\n",
        "\n",
        "# # Create DataLoaders for the subsets\n",
        "# kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
        "# train_loader = DataLoader(train_subset, shuffle=True, batch_size=256, **kwargs)\n",
        "# val_loader = DataLoader(val_subset, batch_size=256, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58erhwFnGr0y"
      },
      "source": [
        "Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Guq_6-nUckv"
      },
      "outputs": [],
      "source": [
        "class DataAugmentation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DataAugmentation, self).__init__()\n",
        "        self.transforms = Compose([\n",
        "            AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "            TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
        "            PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "            TimeMask(min_band_part=0.1, max_band_part=0.15, p=0.5),\n",
        "        ])\n",
        "\n",
        "    def forward(self, song, sample_rate):\n",
        "        augmented_song = self.transforms(song, sample_rate=sample_rate)\n",
        "        return augmented_song"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4vv4yfYLlWP"
      },
      "source": [
        "Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE2oqAvE3VYt"
      },
      "outputs": [],
      "source": [
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, input_data, input_labels, sample_rate=16000, n_mels=128, mean=6.5304, std=11.8924, transform=None):\n",
        "        self.input_data = input_data\n",
        "        self.input_labels = input_labels\n",
        "        self.sr = sample_rate\n",
        "        self.n_mels = n_mels\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.transform = transform\n",
        "        self.mel_spec_transform = T.MelSpectrogram(sample_rate=self.sr, n_mels=self.n_mels, n_fft=2048, hop_length=512)\n",
        "        self.log_mel_spec_transform = T.AmplitudeToDB()\n",
        "        self.image_transforms = transform = v2.Compose([\n",
        "                                                        v2.Resize((64, 64)),\n",
        "                                                        v2.ToImage(),\n",
        "                                                        v2.ToDtype(torch.float32, scale=True),\n",
        "                                                        v2.Normalize((self.mean,), (self.std,))\n",
        "                                                    ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        song = self.input_data[idx]\n",
        "        genre = self.input_labels[idx]\n",
        "        if self.transform:\n",
        "            song = self.transform(song, self.sr)\n",
        "\n",
        "        mel_spec = self.mel_spec_transform(torch.from_numpy(song))\n",
        "        log_mel_spec = self.log_mel_spec_transform(mel_spec)\n",
        "        mel_spec_tensor = log_mel_spec.unsqueeze(0)\n",
        "        mel_spec_tensor = self.image_transforms(mel_spec_tensor)\n",
        "\n",
        "        return mel_spec_tensor, genre\n",
        "\n",
        "audio_train_dataset = AudioDataset(input_data=train_data, input_labels=train_labels, transform=DataAugmentation())\n",
        "audio_val_dataset = AudioDataset(input_data=val_data, input_labels=val_labels, transform=None)\n",
        "\n",
        "audio_train_loader = DataLoader(audio_train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
        "audio_val_loader = DataLoader(audio_val_dataset, batch_size=32, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# From: https://stackoverflow.com/questions/60101240/finding-mean-and-standard-deviation-across-image-channels-pytorch\n",
        "def dataset_mean_std(data_loader):\n",
        "  nimages = 0\n",
        "  mean = 0.\n",
        "  std = 0.\n",
        "  for batch, _ in data_loader:\n",
        "      # Rearrange batch to be the shape of [B, C, W * H]\n",
        "      batch = batch.view(batch.size(0), batch.size(1), -1)\n",
        "      # Update total number of images\n",
        "      nimages += batch.size(0)\n",
        "      # Compute mean and std here\n",
        "      mean += batch.float().mean(2).sum(0)\n",
        "      std += batch.float().std(2).sum(0)\n",
        "\n",
        "  # Final step\n",
        "  mean /= nimages\n",
        "  std /= nimages\n",
        "\n",
        "  print(\"Training set mean\", mean)\n",
        "  print(\"Training set std\", std)\n",
        "\n",
        "  return mean, std\n",
        "\n",
        "def get_mean_std(data):\n",
        "  mean = np.mean(data, axis=(0, 1, 2))\n",
        "  std = np.std(data, axis=(0, 1, 2))\n",
        "  return mean, std"
      ],
      "metadata": {
        "id": "uBJwi4cNtRDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbE0ZJlSAbkL"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbUesLLxhQ4E"
      },
      "source": [
        "Print Layer (debugging)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWc2Rmz9hQNh"
      },
      "outputs": [],
      "source": [
        "class PrintLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PrintLayer, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Do your print / debug stuff here\n",
        "        print(\"X shape:\", x.shape)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b8PGs4MY0lZ"
      },
      "source": [
        "Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvo_HoTlYzod"
      },
      "outputs": [],
      "source": [
        "# From: https://github.com/wzlxjtu/PositionalEncoding2D\n",
        "class PositionalEncoding1d(nn.Module):\n",
        "    def __init__(self, d_model, length):\n",
        "        super(PositionalEncoding1d, self).__init__()\n",
        "        if d_model % 2 != 0:\n",
        "            raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
        "                            \"odd dim (got dim={:d})\".format(d_model))\n",
        "        pe = torch.zeros(length, d_model)\n",
        "        position = torch.arange(0, length).unsqueeze(1)\n",
        "        div_term = torch.exp((torch.arange(0, d_model, 2, dtype=torch.float) *\n",
        "                            -(math.log(10000.0) / d_model)))\n",
        "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe\n",
        "\n",
        "\n",
        "class PositionalEncoding2d(nn.Module):\n",
        "    def __init__(self, d_model, height, width):\n",
        "        super(PositionalEncoding2d, self).__init__()\n",
        "        if d_model % 4 != 0:\n",
        "            raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
        "                            \"odd dimension (got dim={:d})\".format(d_model))\n",
        "        pe = torch.zeros(d_model, height, width)\n",
        "        # Each dimension use half of d_model\n",
        "        d_model = int(d_model / 2)\n",
        "        div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
        "                            -(math.log(10000.0) / d_model))\n",
        "        pos_w = torch.arange(0., width).unsqueeze(1)\n",
        "        pos_h = torch.arange(0., height).unsqueeze(1)\n",
        "        pe[0:d_model:2, :, :] = torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "        pe[1:d_model:2, :, :] = torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "        pe[d_model::2, :, :] = torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "        pe[d_model + 1::2, :, :] = torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq58xQoFurNG"
      },
      "source": [
        "Separable Convolution 2D Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzNfP3uMuuA5"
      },
      "outputs": [],
      "source": [
        "# Inspired by: https://github.com/reshalfahsi/separableconv-torch\n",
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=1, bias=False):\n",
        "        super(SeparableConv2d, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=in_channels, bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "class SeparableConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=1, bias=False):\n",
        "        super(SeparableConv1d, self).__init__()\n",
        "        self.depthwise = nn.Conv1d(in_channels, in_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=in_channels, bias=bias)\n",
        "        self.pointwise = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-nLapjftrVW"
      },
      "source": [
        "Residual Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3f_RdYZtqoS"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, num_layers: int, pool: bool, short: bool, two_dim: bool):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.pooling = pool\n",
        "        self.short = short\n",
        "        self.two_dim = two_dim\n",
        "\n",
        "        self.inconv = nn.Sequential(\n",
        "            SeparableConv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=1, bias=False),\n",
        "            nn.SELU()\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        for _ in range(num_layers - 1):\n",
        "            if self.two_dim:\n",
        "              layers.append(SeparableConv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=1, bias=False))\n",
        "            else:\n",
        "              layers.append(SeparableConv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=1, bias=False))\n",
        "            layers.append(nn.SELU())\n",
        "        self.convlayers = nn.Sequential(*layers)\n",
        "\n",
        "        if self.pooling:\n",
        "            if self.two_dim:\n",
        "              self.pool = nn.MaxPool2d(kernel_size=kernel_size, stride=2, padding=1)\n",
        "              self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2, bias=False)\n",
        "            else:\n",
        "              self.pool = nn.MaxPool1d(kernel_size=kernel_size, stride=2, padding=1)\n",
        "              self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=2, bias=False)\n",
        "        else:\n",
        "            if self.two_dim:\n",
        "              self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "            else:\n",
        "              self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "\n",
        "        self.sact = nn.SELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.inconv(x)\n",
        "        out = self.convlayers(out)\n",
        "\n",
        "        if self.pooling:\n",
        "            out = self.pool(out)\n",
        "\n",
        "        if self.short:\n",
        "            shortcut = self.shortcut(x)\n",
        "            out = out + shortcut\n",
        "            out = self.sact(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN5LxjCdKani"
      },
      "source": [
        "Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TKXXLVXfxHo"
      },
      "outputs": [],
      "source": [
        "class EmbeddingModel(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(EmbeddingModel, self).__init__()\n",
        "      self.input = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                                 nn.SELU())\n",
        "      self.positional_encoding = PositionalEncoding2d(64, 128, 130)\n",
        "\n",
        "\n",
        "      self.conv_layers = nn.Sequential(\n",
        "          ResidualBlock(in_channels=64, out_channels=64, kernel_size=3, num_layers=4, pool=True, short=True, two_dim=True),\n",
        "          ResidualBlock(in_channels=64, out_channels=128, kernel_size=3, num_layers=4, pool=True, short=True, two_dim=True),\n",
        "          ResidualBlock(in_channels=128, out_channels=256, kernel_size=3, num_layers=4, pool=True, short=True, two_dim=True),\n",
        "      )\n",
        "\n",
        "      self.attention = nn.MultiheadAttention(embed_dim=16, num_heads=2, dropout=0.5, batch_first=True)\n",
        "\n",
        "      self.dense_layers = nn.Sequential(\n",
        "          nn.Linear(in_features=256, out_features=512, bias=False),\n",
        "          nn.SELU(),\n",
        "          nn.Linear(in_features=512, out_features=256, bias=False),\n",
        "          nn.SELU(),\n",
        "          nn.Linear(in_features=256, out_features=128, bias=False),\n",
        "          nn.SELU(),\n",
        "          nn.Dropout(0.5),\n",
        "      )\n",
        "\n",
        "      self.output = nn.Linear(128, 8)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.input(x)\n",
        "      # x = F.layer_norm(self.positional_encoding(x), x.shape)\n",
        "      x = self.conv_layers(x)\n",
        "\n",
        "      # batch_size, channels, height, width = x.size()\n",
        "      # x = x.view(batch_size, channels, height * width)\n",
        "      # attention_output, _ = self.attention(x, x, x)\n",
        "      # x = F.layer_norm(x + attention_output, x.shape)\n",
        "\n",
        "      x = torch.mean(x.view(x.size(0), x.size(1), -1), dim=2)\n",
        "      x = self.dense_layers(x)\n",
        "      out = self.output(x)\n",
        "      return out\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "      return self.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqNYS8CbqRvy"
      },
      "outputs": [],
      "source": [
        "# From https://github.com/adambielski/siamese-triplet\n",
        "class SimpleEmbeddingModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleEmbeddingModel, self).__init__()\n",
        "        self.convnet = nn.Sequential(SeparableConv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                                     nn.SELU(),\n",
        "                                     nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "                                     SeparableConv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                                     nn.SELU(),\n",
        "                                     nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "                                     SeparableConv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                                     nn.SELU(),\n",
        "                                     nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "                                    )\n",
        "\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 512),\n",
        "                                nn.SELU(),\n",
        "                                nn.Linear(512, 256),\n",
        "                                nn.SELU(),\n",
        "                                nn.Linear(256, 10)\n",
        "                                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.convnet(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        return self.forward(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvwY-DtHAgIk"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQdZH7di-4FI"
      },
      "source": [
        "Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHfW_2Qv-4-8"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = float('inf')\n",
        "        self.max_accuracy = float('-inf')\n",
        "\n",
        "    def early_stop(self, validation_loss):\n",
        "        if validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def reset_loss(self):\n",
        "        self.min_validation_loss = float('inf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ9LNzJpANwb"
      },
      "source": [
        "Autoclip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq9wL52aANCt"
      },
      "outputs": [],
      "source": [
        "# From: https://github.com/pseeth/autoclip/blob/master/autoclip.py\n",
        "class AutoClip:\n",
        "    def __init__(self, percentile):\n",
        "        self.grad_history = []\n",
        "        self.percentile = percentile\n",
        "\n",
        "    def compute_grad_norm(self, model):\n",
        "        total_norm = 0\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                param_norm = p.grad.data.norm(2)\n",
        "                total_norm += param_norm.item() ** 2\n",
        "        total_norm = total_norm ** (1. / 2)\n",
        "\n",
        "        return total_norm\n",
        "\n",
        "    def __call__(self, model):\n",
        "        grad_norm = self.compute_grad_norm(model)\n",
        "        self.grad_history.append(grad_norm)\n",
        "        clip_value = np.percentile(self.grad_history, self.percentile)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkh_iRGFAkqF"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-c4IZbZAn0f",
        "outputId": "ce6da4f6-6f9c-428d-fe1f-f46118a80c9d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [23:35<00:00,  1.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.801260 - Train Accuracy: 30.625701 - Val loss: 1.652765 - Val Accuracy: 37.492985 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [22:39<00:00,  1.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.654718 - Train Accuracy: 38.643378 - Val loss: 1.538365 - Val Accuracy: 43.637767 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [22:33<00:00,  1.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.568366 - Train Accuracy: 43.308081 - Val loss: 1.472648 - Val Accuracy: 47.334456 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [22:51<00:00,  1.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.514648 - Train Accuracy: 45.803521 - Val loss: 1.437213 - Val Accuracy: 48.947811 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [24:10<00:00,  1.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.482727 - Train Accuracy: 47.183642 - Val loss: 1.371205 - Val Accuracy: 52.244669 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [24:14<00:00,  1.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.446094 - Train Accuracy: 49.039001 - Val loss: 1.357011 - Val Accuracy: 52.321829 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [24:16<00:00,  1.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.420821 - Train Accuracy: 49.935115 - Val loss: 1.352742 - Val Accuracy: 53.065376 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [25:10<00:00,  1.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.403654 - Train Accuracy: 50.801417 - Val loss: 1.335945 - Val Accuracy: 53.514310 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [24:02<00:00,  1.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.393546 - Train Accuracy: 51.234568 - Val loss: 1.319841 - Val Accuracy: 54.306958 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [24:00<00:00,  1.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.387110 - Train Accuracy: 51.508137 - Val loss: 1.313380 - Val Accuracy: 54.391134 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [24:05<00:00,  1.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.432392 - Train Accuracy: 49.568603 - Val loss: 1.339479 - Val Accuracy: 53.030303 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [27:18<00:00,  1.09it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.412357 - Train Accuracy: 50.296366 - Val loss: 1.312589 - Val Accuracy: 53.829966 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [26:31<00:00,  1.12it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.395620 - Train Accuracy: 50.982043 - Val loss: 1.302892 - Val Accuracy: 54.587542 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [24:37<00:00,  1.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.370186 - Train Accuracy: 51.862374 - Val loss: 1.348082 - Val Accuracy: 52.918070 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [25:44<00:00,  1.15it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.352966 - Train Accuracy: 52.756734 - Val loss: 1.259144 - Val Accuracy: 56.649832 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [27:31<00:00,  1.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.329078 - Train Accuracy: 53.609007 - Val loss: 1.248423 - Val Accuracy: 56.797138 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [27:33<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.312415 - Train Accuracy: 54.343785 - Val loss: 1.242330 - Val Accuracy: 57.182941 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [27:11<00:00,  1.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.295244 - Train Accuracy: 55.211841 - Val loss: 1.226500 - Val Accuracy: 57.638889 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [25:55<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.285282 - Train Accuracy: 55.387205 - Val loss: 1.216450 - Val Accuracy: 58.122896 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [26:04<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.276845 - Train Accuracy: 55.764240 - Val loss: 1.209575 - Val Accuracy: 58.228114 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [26:49<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.348571 - Train Accuracy: 52.667298 - Val loss: 1.270971 - Val Accuracy: 56.116723 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [26:50<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.325422 - Train Accuracy: 53.754559 - Val loss: 1.249464 - Val Accuracy: 56.586700 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [25:08<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.306463 - Train Accuracy: 54.752385 - Val loss: 1.226372 - Val Accuracy: 57.168911 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [24:49<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.295480 - Train Accuracy: 54.838314 - Val loss: 1.213139 - Val Accuracy: 58.045735 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [24:37<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.273799 - Train Accuracy: 55.939604 - Val loss: 1.186977 - Val Accuracy: 59.343434 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [23:58<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.257190 - Train Accuracy: 56.413089 - Val loss: 1.172355 - Val Accuracy: 59.750281 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [23:26<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.237622 - Train Accuracy: 57.370581 - Val loss: 1.160795 - Val Accuracy: 59.841470 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [23:25<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.220284 - Train Accuracy: 57.849327 - Val loss: 1.145339 - Val Accuracy: 60.353535 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [25:57<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.209388 - Train Accuracy: 58.066779 - Val loss: 1.149546 - Val Accuracy: 60.325477 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [25:43<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.197581 - Train Accuracy: 58.699846 - Val loss: 1.138188 - Val Accuracy: 60.928732 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [24:52<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.269721 - Train Accuracy: 55.929082 - Val loss: 1.196634 - Val Accuracy: 58.501684 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [25:32<00:00,  1.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.264973 - Train Accuracy: 56.092172 - Val loss: 1.200645 - Val Accuracy: 59.238215 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [25:14<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.250956 - Train Accuracy: 56.477974 - Val loss: 1.165993 - Val Accuracy: 59.792368 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [22:37<00:00,  1.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.242356 - Train Accuracy: 57.089997 - Val loss: 1.148438 - Val Accuracy: 60.521886 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [22:40<00:00,  1.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.218320 - Train Accuracy: 57.894921 - Val loss: 1.133758 - Val Accuracy: 60.816498 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [23:36<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.191012 - Train Accuracy: 58.954125 - Val loss: 1.128328 - Val Accuracy: 61.251403 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [24:45<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.174236 - Train Accuracy: 59.560887 - Val loss: 1.115325 - Val Accuracy: 61.489899 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [25:03<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.161917 - Train Accuracy: 59.888819 - Val loss: 1.092796 - Val Accuracy: 62.324635 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [24:31<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.143162 - Train Accuracy: 60.769150 - Val loss: 1.088825 - Val Accuracy: 62.394781 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [24:34<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.141420 - Train Accuracy: 60.725309 - Val loss: 1.081990 - Val Accuracy: 62.682379 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [24:17<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.228840 - Train Accuracy: 57.286406 - Val loss: 1.192172 - Val Accuracy: 59.245230 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [24:10<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.207836 - Train Accuracy: 58.345609 - Val loss: 1.130114 - Val Accuracy: 61.328563 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [24:08<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.192830 - Train Accuracy: 58.843645 - Val loss: 1.110615 - Val Accuracy: 61.679293 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [23:56<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.184874 - Train Accuracy: 59.020763 - Val loss: 1.149570 - Val Accuracy: 60.949776 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [24:07<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.162871 - Train Accuracy: 60.043140 - Val loss: 1.121566 - Val Accuracy: 61.293490 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [23:39<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.144763 - Train Accuracy: 60.539422 - Val loss: 1.082865 - Val Accuracy: 62.415825 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1782/1782 [23:26<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.126226 - Train Accuracy: 61.228605 - Val loss: 1.058900 - Val Accuracy: 63.517116 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 1044/1782 [14:07<10:00,  1.23it/s]"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "cuda = torch.cuda.is_available()\n",
        "embedding_model = EmbeddingModel().to(device)\n",
        "simple_embedding_model = SimpleEmbeddingModel().to(device)\n",
        "\n",
        "num_epochs = 50\n",
        "learning_rate = 1e-4\n",
        "classification_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.AdamW(embedding_model.parameters(), lr=learning_rate, weight_decay=1e-2)\n",
        "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=10)\n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "autoclipper = AutoClip(percentile=10)\n",
        "\n",
        "def train_loop(train_loader, model, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    num_batches = len(train_loader)\n",
        "\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Training loop\n",
        "    for batch, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
        "        optimizer.zero_grad()\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, targets)\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        scaler.scale(loss).backward()\n",
        "        autoclipper(model)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_correct += (predicted == targets).sum().item()\n",
        "        total_samples += targets.size(0)\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "        scale = scaler.get_scale()\n",
        "        scaler.update()\n",
        "        skip_lr_sched = (scale != scaler.get_scale())\n",
        "\n",
        "    accuracy = 100 * total_correct / total_samples\n",
        "    train_loss = train_loss / num_batches\n",
        "    return train_loss, accuracy, skip_lr_sched\n",
        "\n",
        "def val_loop(val_loader, model, criterion, device, epoch):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    num_batches = len(val_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_correct += (predicted == targets).sum().item()\n",
        "            total_samples += targets.size(0)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    accuracy = 100 * total_correct / total_samples\n",
        "    val_loss /= num_batches\n",
        "    return val_loss, accuracy\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loss, train_accuracy, skip_lr_sched = train_loop(audio_train_loader, embedding_model, classification_loss_fn, optimizer, device, epoch+1)\n",
        "    val_loss, val_accuracy = val_loop(audio_val_loader, embedding_model, classification_loss_fn, device, epoch+1)\n",
        "    print(f\"Train loss: {train_loss:>8f} - Train Accuracy: {train_accuracy:>f} - Val loss: {val_loss:>8f} - Val Accuracy: {val_accuracy:>f} \\n\")\n",
        "\n",
        "    # early_stop_result = early_stopping.early_stop(val_loss)\n",
        "    # if early_stop_result:\n",
        "    #     print(f\"Early stopping after {epoch+1} epochs \\n\")\n",
        "    #     print(f\"Best val loss: {early_stopping.min_validation_loss} \\n\")\n",
        "    #     break\n",
        "\n",
        "    if not skip_lr_sched:\n",
        "        scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw3nYWqqKkKw"
      },
      "outputs": [],
      "source": [
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "HvwY-DtHAgIk"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}